{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCsbAMdMDVEP",
        "outputId": "2bd30b66-5f84-40a9-e332-530d1227ed37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running XGBoost (Python + 5-fold CV)\n",
            "----------------------------------------\n",
            "\n",
            "Dataset Size: 100 | File: generated_data_100.csv\n",
            "Loaded 100 rows in 0.01s\n",
            "Running cross-validation...\n",
            "CV Time: 3.10s | Accuracy: 0.9400\n",
            "\n",
            "Dataset Size: 1000 | File: generated_data_1000.csv\n",
            "Loaded 1000 rows in 0.01s\n",
            "Running cross-validation...\n",
            "CV Time: 0.42s | Accuracy: 0.9520\n",
            "\n",
            "Dataset Size: 10000 | File: generated_data_10000.csv\n",
            "Loaded 10000 rows in 0.02s\n",
            "Running cross-validation...\n",
            "CV Time: 1.44s | Accuracy: 0.9755\n",
            "\n",
            "Dataset Size: 100000 | File: generated_data_1e+05.csv\n",
            "Loaded 100000 rows in 0.14s\n",
            "Running cross-validation...\n",
            "CV Time: 4.46s | Accuracy: 0.9868\n",
            "\n",
            "Dataset Size: 1000000 | File: generated_data_1e+06.csv\n",
            "Loaded 1000000 rows in 1.06s\n",
            "Running cross-validation...\n",
            "CV Time: 51.62s | Accuracy: 0.9917\n",
            "\n",
            "Dataset Size: 10000000 | File: generated_data_1e+07.csv\n",
            "Loaded 10000000 rows in 7.73s\n",
            "Running cross-validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV Time: 427.75s | Accuracy: 0.9931\n",
            "\n",
            "==================================================\n",
            "Summary of XGBoost (Python 5-fold CV)\n",
            "==================================================\n",
            "                    Method  Dataset size  Testing-set predictive performance  Time taken for the model to be fit (s)\n",
            "XGBoost (Python 5-fold CV)           100                              0.9400                                    3.10\n",
            "XGBoost (Python 5-fold CV)          1000                              0.9520                                    0.42\n",
            "XGBoost (Python 5-fold CV)         10000                              0.9755                                    1.44\n",
            "XGBoost (Python 5-fold CV)        100000                              0.9868                                    4.46\n",
            "XGBoost (Python 5-fold CV)       1000000                              0.9917                                   51.62\n",
            "XGBoost (Python 5-fold CV)      10000000                              0.9931                                  427.75\n",
            "\n",
            "Saved results to xgb_python_results.csv\n"
          ]
        }
      ],
      "source": [
        "#Import necessary libraries\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Mapping dataset sizes to their corresponding CSV filenames\n",
        "files = {\n",
        "    100: \"generated_data_100.csv\",\n",
        "    1000: \"generated_data_1000.csv\",\n",
        "    10000: \"generated_data_10000.csv\",\n",
        "    100000: \"generated_data_1e+05.csv\",\n",
        "    1000000: \"generated_data_1e+06.csv\",\n",
        "    10000000: \"generated_data_1e+07.csv\"\n",
        "}\n",
        "\n",
        "# Predictor columns and outcome column\n",
        "cols_x = ['pregnant', 'glucose', 'pressure', 'triceps', 'insulin', 'mass', 'pedigree', 'age']\n",
        "col_y = 'outcome'\n",
        "folds = 5  # Number of folds for cross-validation\n",
        "\n",
        "def run_cv(X, y, folds=5):\n",
        "    \"\"\"\n",
        "    Runs XGBoost classification using scikit-learn's cross_val_score.\n",
        "\n",
        "    Parameters:\n",
        "    X (DataFrame): Predictor variables.\n",
        "    y (Series): Outcome variable (binary classification).\n",
        "    folds (int): Number of CV folds.\n",
        "\n",
        "    Returns:\n",
        "    Tuple: mean accuracy score, time taken for fitting\n",
        "    \"\"\"\n",
        "    model = xgb.XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        eval_metric='logloss',\n",
        "        use_label_encoder=False,\n",
        "        n_jobs=-1,\n",
        "        verbosity=0\n",
        "    )\n",
        "    cv = KFold(n_splits=folds, shuffle=True, random_state=42)  # 5-fold CV\n",
        "    start = time.time()\n",
        "    acc = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    end = time.time()\n",
        "    return np.mean(acc), end - start\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to process all datasets, run XGBoost with 5-fold CV,\n",
        "    and store results in a summary table.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    print(\"Running XGBoost (Python + 5-fold CV)\\n\" + \"-\"*40)\n",
        "\n",
        "    for sz, fname in files.items():\n",
        "        print(f\"\\nDataset Size: {sz} | File: {fname}\")\n",
        "\n",
        "        try:\n",
        "            # Check if the file exists\n",
        "            if not os.path.exists(fname):\n",
        "                raise FileNotFoundError(f\"File not found: {fname}\")\n",
        "\n",
        "            # Load data and measure load time\n",
        "            t_load = time.time()\n",
        "            df = pd.read_csv(fname)\n",
        "            print(f\"Loaded {len(df)} rows in {time.time() - t_load:.2f}s\")\n",
        "\n",
        "            # Check for necessary columns\n",
        "            required_cols = cols_x + [col_y]\n",
        "            if not all(col in df.columns for col in required_cols):\n",
        "                raise ValueError(f\"Missing columns. Found: {df.columns.tolist()}\")\n",
        "\n",
        "            # Drop rows with missing values\n",
        "            before_rows = len(df)\n",
        "            df = df.dropna(subset=required_cols)\n",
        "            dropped = before_rows - len(df)\n",
        "            if dropped > 0:\n",
        "                print(f\"Dropped {dropped} rows with missing values\")\n",
        "\n",
        "            # Split into predictors and target\n",
        "            X = df[cols_x]\n",
        "            y = df[col_y].astype(int)\n",
        "\n",
        "            print(\"Running cross-validation...\")\n",
        "            acc, t_cv = run_cv(X, y, folds)\n",
        "            print(f\"CV Time: {t_cv:.2f}s | Accuracy: {acc:.4f}\")\n",
        "\n",
        "            # Append result to list\n",
        "            results.append({\n",
        "                \"Method\": \"XGBoost (Python 5-fold CV)\",\n",
        "                \"Dataset size\": sz,\n",
        "                \"Testing-set predictive performance\": round(acc, 4),\n",
        "                \"Time taken for the model to be fit (s)\": round(t_cv, 2)\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle errors (e.g., file not found, missing columns, etc.)\n",
        "            print(f\"Error: {e}\")\n",
        "            results.append({\n",
        "                \"Method\": \"XGBoost (Python 5-fold CV)\",\n",
        "                \"Dataset size\": sz,\n",
        "                \"Testing-set predictive performance\": \"Error\",\n",
        "                \"Time taken for the model to be fit (s)\": \"Error\"\n",
        "            })\n",
        "\n",
        "    # Display and save final results\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"Summary of XGBoost (Python 5-fold CV)\")\n",
        "    print(\"=\"*50)\n",
        "    df_results = pd.DataFrame(results)\n",
        "    print(df_results.to_string(index=False))\n",
        "\n",
        "    # Save to CSV\n",
        "    df_results.to_csv(\"xgb_python_results.csv\", index=False)\n",
        "    print(\"\\nSaved results to xgb_python_results.csv\")\n",
        "\n",
        "# Entry point of the script\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}