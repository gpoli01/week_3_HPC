{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: Greeshma POli\n",
        "\n",
        "Banner Id: 001335934\n",
        "\n",
        "Subject: High Performance Computing\n",
        "\n",
        "Week 09 - Machine Learning with Scikit-learn"
      ],
      "metadata": {
        "id": "4ANmWxAD62GV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Among the different classification models included in the Python notebook, which model had the best overall performance? Support your response by referencing appropriate evidence.\n",
        "\n",
        "Answer: Among all the classification models tested, the Logistic Regression model with L1 regularization and C=10, using the liblinear solver, gave the best overall results.\n",
        "\n",
        "This model had a test accuracy of 0.718, which was the highest among all the logistic regression versions. Interestingly, the basic logistic regression model (without regularization) also had a test accuracy of 0.718, but the L1 regularization likely made the model better at generalizing by helping it focus on the most important features. This is especially useful in healthcare, where we want models to be easy to understand.\n",
        "\n",
        "The Random Forest models had very high training accuracy (almost 1.0), but lower test accuracy. This means they overfit—they learned the training data too well and didn’t perform as well on new data.\n",
        "\n",
        "Overall, the liblinear solver worked really well, especially with L1 regularization. It’s a good choice for small datasets and helps with feature selection. So, the Logistic_L1_C_10 model strikes the best balance between accuracy and generalization, making it the top-performing model in this case."
      ],
      "metadata": {
        "id": "TFCxmmOq8qMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Next, fit a series of logistic regression models, without regularization. Each model should use the same set of predictors (all of the relevant predictors in the dataset) and should use the entire dataset, rather than a fraction of it. Use a randomly chosen 80% proportion of observations for training and the remaining for checking the generalizable performance (i.e., performance on the holdout subset). Be sure to ensure that the training and holdout subsets are identical across all models. Each model should choose a different solver.\n"
      ],
      "metadata": {
        "id": "_EdbLJf5BtGU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Compare the results of the models in terms of their accuracy (use this as the performance metric to assess generalizability error on the holdout subset) and the time taken (use appropriate timing function). Summarize your results via a table with the following structure:\n",
        "\n",
        "Solver used\n",
        "\n",
        "Training subset accuracy\n",
        "\n",
        "Holdout subset accuracy\n",
        "\n",
        "Time taken"
      ],
      "metadata": {
        "id": "9TTOE-oyBvAJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFLbgaPJ5V2a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from patsy import dmatrices\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Loading and prepare the dataset\n",
        "df = pd.read_csv(\"PatientAnalyticFile.csv\")"
      ],
      "metadata": {
        "id": "URRo3EUJ5fB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create mortality column: 1 if DateOfDeath exists, else 0\n",
        "df[\"mortality\"] = np.where(df[\"DateOfDeath\"].isnull(), 0, 1)"
      ],
      "metadata": {
        "id": "MSs7u8M65l5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate age in years\n",
        "df[\"DateOfBirth\"] = pd.to_datetime(df[\"DateOfBirth\"], errors='coerce')\n",
        "df[\"Age_years\"] = ((pd.to_datetime(\"2015-01-01\") - df[\"DateOfBirth\"]).dt.days / 365.25)"
      ],
      "metadata": {
        "id": "S9Rb1MzS5sJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns that should not be used as predictors\n",
        "vars_remove = [\"PatientID\", \"First_Appointment_Date\", \"DateOfBirth\",\n",
        "               \"Last_Appointment_Date\", \"DateOfDeath\", \"mortality\"]\n",
        "vars_left = list(set(df.columns) - set(vars_remove))"
      ],
      "metadata": {
        "id": "0HZ9HMK05xTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the regression formula\n",
        "formula = \"mortality ~ \" + \" + \".join(vars_left)\n"
      ],
      "metadata": {
        "id": "B4GLD4wM5z7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a design matrices for logistic regression\n",
        "y, X = dmatrices(formula, df, return_type='dataframe')\n",
        "y = np.ravel(y)  # Flatten target array"
      ],
      "metadata": {
        "id": "4X-QY7Jn52la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset (same split for all models)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "iYezAGnw6Hhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to hold results\n",
        "results = {}\n",
        "# Define solvers here\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "\n",
        "# Loop through each solver and evaluate model\n",
        "for solver in solvers:\n",
        "    try:\n",
        "        start = time.time()\n",
        "\n",
        "        # Initialize and fit the model\n",
        "        model = LogisticRegression(solver=solver, max_iter=1000, fit_intercept=True)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        end = time.time()\n",
        "        elapsed = round(end - start, 4)\n",
        "\n",
        "        # Predict and calculate accuracies\n",
        "        train_pred = model.predict(X_train)\n",
        "        test_pred = model.predict(X_test)\n",
        "        train_acc = round(accuracy_score(y_train, train_pred), 4)\n",
        "        test_acc = round(accuracy_score(y_test, test_pred), 4)\n",
        "\n",
        "        # Store results\n",
        "        results[solver] = {\n",
        "            'Train Accuracy': train_acc,\n",
        "            'Test Accuracy': test_acc,\n",
        "            'Time Taken (s)': elapsed\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        results[solver] = {\n",
        "            'Train Accuracy': 'Error',\n",
        "            'Test Accuracy': 'Error',\n",
        "            'Time Taken (s)': str(e)\n",
        "        }\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qn9WTrq6L8G",
        "outputId": "57868972-2240-4539-fb3c-668db425ae52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Train Accuracy  Test Accuracy  Time Taken (s)\n",
            "newton-cg          0.7482         0.7362          0.0937\n",
            "lbfgs              0.7482         0.7358          0.7068\n",
            "liblinear          0.7479         0.7362          0.0478\n",
            "sag                0.7481         0.7362          9.9994\n",
            "saga               0.7480         0.7362         14.3261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Based on the results, which solver yielded the best results? Explain the basis for ranking the models - did you use training subset accuracy? Holdout subset accuracy? Time of execution? All three? Some combination of the three?\n",
        "\n",
        "Answer: Based on the results, the lbfgs solver gave the best overall performance. It had the highest test accuracy of 0.7365, which is important because test accuracy shows how well the model performs on new, unseen data. While other solvers like newton-cg, liblinear, sag, and saga had similar test accuracies (around 0.7362), they were either slightly lower or the same. I focused mainly on test accuracy to compare the models, since that's a better measure of generalization than training accuracy. However, I also considered time of execution. For example, liblinear was the fastest (0.0558 seconds), but its test accuracy was a bit lower. On the other hand, sag and saga took the longest time to run (over 11 and 13 seconds) and still didn’t show better accuracy. They also triggered ConvergenceWarnings, meaning they didn’t fully finish optimizing within the allowed number of iterations. So, when balancing accuracy, time, and stability, lbfgs is the best choice among all solvers in this case."
      ],
      "metadata": {
        "id": "ipnhcuw46RII"
      }
    }
  ]
}